{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Webcam as input source of the Composable Pipeline\n",
    "----\n",
    "\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "Please use Jupyter labs http://&lt;board_ip_address&gt;/lab for this notebook.\n",
    "</div>\n",
    "\n",
    "This notebook shows your how to use a Webcam as a input source for your composable pipeline\n",
    "\n",
    "## Aims\n",
    "* Use Webcam as an input video source\n",
    "* Compose a video pipeline over the webcam stream\n",
    "\n",
    "## Table of Contents\n",
    "* [Download Composable Overlay](#download)\n",
    "* [Configure Webcam](#setup_cam)\n",
    "* [Compose a Simple Pipeline](#simple-pipeline)\n",
    "* [Compose Complex Pipeline](#complex-pipeline)\n",
    "* [Modify Parameters](#parameters)\n",
    "* [Stop Webcam Video](#stop_web)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "----\n",
    "\n",
    "## Revision History\n",
    "\n",
    "* v1.0 | 21 June 2021 | First notebook revision.\n",
    "* v1.1 | 11 August 2021 | Update notebook to composable overlay API 1.0.0\n",
    "* v1.2 | 27 September 2021 | Update notebook to use `VideoStream`\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Composable Overlay <a class=\"anchor\" id=\"download\"></a>\n",
    "\n",
    "Import the pynq video libraries as well as Composable class and the drivers for the IP.\n",
    "\n",
    "Download the Composable Overlay using `pynq.Overlay` and grab a handler to the `composable` hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq.lib.video import *\n",
    "from pynq_composable import *\n",
    "from ipywidgets import widgets, interact, FloatSlider, IntSlider\n",
    "from pynq.ps import CPU_ARCH, ZYNQ_ARCH\n",
    "\n",
    "ol = Overlay(\"cv_dfx_4_pr.bit\")\n",
    "\n",
    "cpipe = ol.composable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Webcam <a class=\"anchor\" id=\"setup_cam\"></a>\n",
    "\n",
    "Configure the Webcam and with `VideoStream` class, and start the video\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\">\n",
    "    <h4 class=\"alert-heading\">Warning:</h4>\n",
    "\n",
    "Failure to connect HDMI output cable to an screen may cause the notebook to hang\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoStream(ol, source=VSource.OpenCV)\n",
    "\n",
    "video.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose Simple Pipeline <a class=\"anchor\" id=\"simple-pipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab handlers to LUT and compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = cpipe.lut_accel\n",
    "lut.kernel_type = xvLut.negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpipe.compose([cpipe.hdmi_sink_in, lut, cpipe.hdmi_sink_out])\n",
    "cpipe.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose Complex Pipeline <a class=\"anchor\" id=\"complex-pipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\">\n",
    "    <h4 class=\"alert-heading\">Warning:</h4>\n",
    "\n",
    "Failure to pause the VideoStream for Zynq-7000 devices before using `.loadIP` may cause the notebook to hang\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook, we will bring new functionality into the DFX regions to compose a corner detect application. \n",
    "\n",
    "Load dynamic IP, grab handlers and set up default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CPU_ARCH != ZYNQ_ARCH:\n",
    "    video.pause()\n",
    "\n",
    "cpipe.loadIP(['pr_0/fast_accel', 'pr_fork/duplicate_accel', 'pr_join/add_accel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resume Webcam stream\n",
    "if CPU_ARCH != ZYNQ_ARCH:\n",
    "    video.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab handler to functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = cpipe.pr_0.fast_accel\n",
    "duplicate = cpipe.pr_fork.duplicate_accel\n",
    "add = cpipe.pr_join.add_accel\n",
    "r2g = cpipe.rgb2gray_accel\n",
    "g2r = cpipe.gray2rgb_accel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Corner Detect is realized by adding (masking) the output of the Fast algorithm to the original image. In the Composable Overlay this is achieved by branching the pipeline, which is expressed as a list of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_pipeline = [cpipe.hdmi_sink_in, duplicate, [[r2g, fast, g2r], [1]], add, cpipe.hdmi_sink_out]\n",
    "\n",
    "cpipe.compose(video_pipeline)\n",
    "\n",
    "cpipe.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Parameters <a class=\"anchor\" id=\"parameters\"></a>\n",
    "\n",
    "The corner Harris IP provides two parameters that help us tweak the sensitivity of the algorithm. These parameters are the threshold and k (Harris parameter), after running the next cell you will be able to update them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = IntSlider(min=0, max=255, step=1, value=25)\n",
    "def play(thr):\n",
    "    fast.threshold = thr\n",
    "\n",
    "interact(play, thr=thr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Webcam Video <a class=\"anchor\" id=\"stop_web\"></a>\n",
    "\n",
    "Finally stop the video stream\n",
    "\n",
    "<div class=\"alert alert-heading alert-danger\">\n",
    "    <h4 class=\"alert-heading\">Warning:</h4>\n",
    "\n",
    "Failure to stop video stream may hang the board \n",
    "when trying to download another bitstream onto the FPGA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.stop()\n",
    "ol.free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Conclusion <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "This notebook has shown how to compose a video pipeline using a Webcam as a video source\n",
    "\n",
    "[⬅️ Advanced Features](07_advanced_features.ipynb) | | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2021 Xilinx, Inc\n",
    "\n",
    "SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
